{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Order For Piwpiw Bakery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Piwpiw Bakery is a bakery shop that sells pastries and baked goods on the TikTok platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Business Goal \n",
    "At Piwpiw Bakery, they offer a special product called \"รักหนูมั๊ยย 3 กระปุก\" for 100 baht. With this offer, customers can select three items from our menu of delightful treats. However, to ensure smooth processing, we kindly request customers to note their choices in the Buyer Message section during checkout, which makes it challenging for them to count orders accurately.\n",
    "\n",
    "\n",
    "Objective \n",
    "\n",
    "1. Use machine learning to accurately count each order with more than 80% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.The dataset\n",
    "\n",
    "- Get dataset from titok seller shop which seperate data for each customer date order \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Planning for counting orders using machine learning \n",
    "\n",
    "1. Data Collection: Gather a dataset containing information about past orders, including item descriptions, quantities, and customer preferences.\n",
    "2. Data Preprocessing: Clean and preprocess the dataset, which may involve removing any irrelevant information, handling missing data, and converting text data into a format suitable for machine learning algorithms.\n",
    "3. Feature Engineering: Extract relevant features from the dataset that can help predict the accuracy of order counts. This could include features such as item descriptions and quantities.\n",
    "4. Splitting the Data: Use train_test_split from sklearn.model_selection to split the dataset into training and testing sets. The training set will be used to train the machine learning model, while the testing set will be used to evaluate its performance.\n",
    "5. Feature Extraction: Utilize TfidfVectorizer from sklearn.feature_extraction.text to convert text data into numerical vectors, which can be used as input for machine learning algorithms.\n",
    "6. Model Selection and Training: Choose an appropriate machine learning model, such as LogisticRegression from sklearn.linear_model, and train it using the training data.\n",
    "7. Evaluation: Evaluate the performance of the trained model using metrics such as accuracy score and classification report from sklearn.metrics. Aim for an accuracy of more than 80%.\n",
    "8. Iterative Improvement: Iterate on the model, adjusting parameters and features as needed to improve performance until the desired accuracy is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Install Pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Gathering for Training in thai language\n",
    "\n",
    "\n",
    "Customers have several ways to describe the order name in the Buyer Message, which I have collected and separated into each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Read dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_category = pd.read_excel('Label/Order_Categories.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_category = order_category.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cube_ori_check', 'cube_chocship_check', 'cube_mango_check',\n",
       "       'cube_almond_check', 'cracker_ori', 'cracker_choc', 'cracker_mango',\n",
       "       'cracker_almond', 'oreo_ori', 'oreo_choc', 'oreo_mango', 'oreo_almond',\n",
       "       'oreo_kitkat', 'cookie_butter', 'cookie_coco', 'cookie_coffee',\n",
       "       'cookie_matcha', 'tart_ori', 'tart_choc', 'tart_mango', 'tart_almond',\n",
       "       'brownie_mash', 'stick', 'chocball'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_category.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cube_ori_check</th>\n",
       "      <th>cube_chocship_check</th>\n",
       "      <th>cube_mango_check</th>\n",
       "      <th>cube_almond_check</th>\n",
       "      <th>cracker_ori</th>\n",
       "      <th>cracker_choc</th>\n",
       "      <th>cracker_mango</th>\n",
       "      <th>cracker_almond</th>\n",
       "      <th>oreo_ori</th>\n",
       "      <th>oreo_choc</th>\n",
       "      <th>...</th>\n",
       "      <th>cookie_coco</th>\n",
       "      <th>cookie_coffee</th>\n",
       "      <th>cookie_matcha</th>\n",
       "      <th>tart_ori</th>\n",
       "      <th>tart_choc</th>\n",
       "      <th>tart_mango</th>\n",
       "      <th>tart_almond</th>\n",
       "      <th>brownie_mash</th>\n",
       "      <th>stick</th>\n",
       "      <th>chocball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>คิวบ์ออริ</td>\n",
       "      <td>คิวบ์ช็อคชิพ</td>\n",
       "      <td>คิวบ์เม็ดมะม่วง</td>\n",
       "      <td>คิวบ์อัลม่อน</td>\n",
       "      <td>แครกเกอร์ออริ</td>\n",
       "      <td>แครกเกอร์ช็อคชิพ</td>\n",
       "      <td>แครกเกอร์เม็ดมะม่วง</td>\n",
       "      <td>แครกเกอร์อัลม่อน</td>\n",
       "      <td>โอริโอออริ</td>\n",
       "      <td>โอริโอช็อคชิพ</td>\n",
       "      <td>...</td>\n",
       "      <td>คุ้กกี้โกโก้</td>\n",
       "      <td>คุ้กกี้กาแฟ</td>\n",
       "      <td>คุ้กกี้มัทฉะ</td>\n",
       "      <td>ทาร์ตบราวนี่ออริ</td>\n",
       "      <td>ทาร์ตบราวนี่ช้อคชิพ</td>\n",
       "      <td>ทาร์ตบราวนี่มะม่วง</td>\n",
       "      <td>ทาร์ตบราวนี่อัลม่อน</td>\n",
       "      <td>บราวนี่มาร์ชแมลโลว์</td>\n",
       "      <td>ปังแท่ง</td>\n",
       "      <td>ช็อคบอล</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>คิวบ์ออริจินัล</td>\n",
       "      <td>คิวบ์ช้อคชิพ</td>\n",
       "      <td>คิวบ์มะม่วง</td>\n",
       "      <td>คิวอัลมอน</td>\n",
       "      <td>แครกเกอร์ออริจินัล</td>\n",
       "      <td>แครกเกอร์ช้อคชิพ</td>\n",
       "      <td>แครกเกอร์มะม่วง</td>\n",
       "      <td>แครกเกอร์อัลม่อน</td>\n",
       "      <td>โอริโอ ออริ</td>\n",
       "      <td>โอริโอช้อคชิพ</td>\n",
       "      <td>...</td>\n",
       "      <td>คุกกี้โก้โก้</td>\n",
       "      <td>คุกกี้กาแฟ</td>\n",
       "      <td>คุกกี้มัดฉะ</td>\n",
       "      <td>ทาร์ตบราวนี่</td>\n",
       "      <td>ทาร์ตช็อคชิพ</td>\n",
       "      <td>ทาร์ตหน้าเม็ดมะม่วง</td>\n",
       "      <td>ทาร์ตอัลมอนด์</td>\n",
       "      <td>บราวนี่มาชเมลโล่</td>\n",
       "      <td>ปังแท่งช้อค</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>คิวบ์ ออริจินอล</td>\n",
       "      <td>คิ้วบ์ช็อคชิพ</td>\n",
       "      <td>คิวมะม่วง</td>\n",
       "      <td>คิวบ์อัลมอน</td>\n",
       "      <td>แครกเกอร์ออริ</td>\n",
       "      <td>แคร็กเกอร์ช็อคชิพ</td>\n",
       "      <td>แครกเกอร์มะม่วงหิมพานต์</td>\n",
       "      <td>แครกเกอร์อัลมอนด</td>\n",
       "      <td>โอริโอ้บราวนี่ ออริจินอล</td>\n",
       "      <td>โอริโอ้บราวนี่ ช็อคชิพ</td>\n",
       "      <td>...</td>\n",
       "      <td>คุกกี้ซ็อก</td>\n",
       "      <td>คุกกกี้กาแฟ</td>\n",
       "      <td>คุกกี้มัmฉะ</td>\n",
       "      <td>ทาร์ตบราวนี่</td>\n",
       "      <td>ทาร์ตบราวนี่ ช็อคชิพ</td>\n",
       "      <td>ทาร์ตบราวนี่ เม็ดมะม่วง</td>\n",
       "      <td>ทาร์ตบราวนี่หน้าอัลมอน</td>\n",
       "      <td>มาร์ชเมลโล่บราวนี่</td>\n",
       "      <td>ปังแห้ง</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>คิ้วบ์ออริ</td>\n",
       "      <td>คิ้ว ช็อกชิพ</td>\n",
       "      <td>คิวบ์เม็ดมะม่วง</td>\n",
       "      <td>คิ้วบ์อัลมอนด์</td>\n",
       "      <td>แครกเกอร์ออลริจินอล</td>\n",
       "      <td>แครกเกอร์ ช็อคชิพ</td>\n",
       "      <td>แค็กมะม่วง</td>\n",
       "      <td>แคกเกอร์อัลมอน</td>\n",
       "      <td>โอริโอ้บราวนี่ออริ</td>\n",
       "      <td>โอริโอ้ช็อกชิพ</td>\n",
       "      <td>...</td>\n",
       "      <td>คุกกี้ช้อก</td>\n",
       "      <td>คุกกี้กาเเฟ</td>\n",
       "      <td>คุ้กกี้มัจฉะ</td>\n",
       "      <td>ทาร์ตออริ</td>\n",
       "      <td>ทาร์ตบราวนี่ช็อคชิพ</td>\n",
       "      <td>ทาตบาวนี่เม็ดมะม่วง</td>\n",
       "      <td>ทาร์ตบราวนี่อัลมอล</td>\n",
       "      <td>บราวนี่มาชเมนโลว</td>\n",
       "      <td>ปังเเท่ง</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>คิวบ์ออลริจินอล</td>\n",
       "      <td>คิ้วท์ชอคชิพ</td>\n",
       "      <td>คิวเม็ดมะม่วง</td>\n",
       "      <td>คิวอัดลมอนด์</td>\n",
       "      <td>แครกเกอร์บราวนี่</td>\n",
       "      <td>แครกเกอร์ช็อกชิพ</td>\n",
       "      <td>แครกเกอร์บราวนี่มะม่วงหิมพานต์</td>\n",
       "      <td>แคกเกอร์อัลมอนด์</td>\n",
       "      <td>โอริโอ้ บราวนี่</td>\n",
       "      <td>โอรีโอ้ช็อคชิพ</td>\n",
       "      <td>...</td>\n",
       "      <td>คุกกี้โกโก้</td>\n",
       "      <td>NaN</td>\n",
       "      <td>คุกกี้มัจฉะ</td>\n",
       "      <td>ทาร์ตบราวนี่</td>\n",
       "      <td>ทาร์ตช็อกชิพ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ทาร์อัดลมอนด์</td>\n",
       "      <td>มาชเมลโล่</td>\n",
       "      <td>ปังแท่งดาร์กช๊อก</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NaN</td>\n",
       "      <td>บราวนี่ช็อกชิพ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NaN</td>\n",
       "      <td>บราวนี่่ช็อกชิฟ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>โอริโอ้ช้อกชิพ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>บราวนี่ช๊อคชิพ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NaN</td>\n",
       "      <td>บราวนี่ช็อคโกเเลตชิพ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cube_ori_check   cube_chocship_check cube_mango_check cube_almond_check  \\\n",
       "0         คิวบ์ออริ          คิวบ์ช็อคชิพ  คิวบ์เม็ดมะม่วง      คิวบ์อัลม่อน   \n",
       "1    คิวบ์ออริจินัล          คิวบ์ช้อคชิพ      คิวบ์มะม่วง         คิวอัลมอน   \n",
       "2   คิวบ์ ออริจินอล         คิ้วบ์ช็อคชิพ        คิวมะม่วง       คิวบ์อัลมอน   \n",
       "3        คิ้วบ์ออริ          คิ้ว ช็อกชิพ  คิวบ์เม็ดมะม่วง    คิ้วบ์อัลมอนด์   \n",
       "4   คิวบ์ออลริจินอล          คิ้วท์ชอคชิพ    คิวเม็ดมะม่วง      คิวอัดลมอนด์   \n",
       "..              ...                   ...              ...               ...   \n",
       "62              NaN        บราวนี่ช็อกชิพ              NaN               NaN   \n",
       "63              NaN       บราวนี่่ช็อกชิฟ              NaN               NaN   \n",
       "64              NaN        โอริโอ้ช้อกชิพ              NaN               NaN   \n",
       "65              NaN        บราวนี่ช๊อคชิพ              NaN               NaN   \n",
       "66              NaN  บราวนี่ช็อคโกเเลตชิพ              NaN               NaN   \n",
       "\n",
       "            cracker_ori       cracker_choc                   cracker_mango  \\\n",
       "0         แครกเกอร์ออริ   แครกเกอร์ช็อคชิพ             แครกเกอร์เม็ดมะม่วง   \n",
       "1    แครกเกอร์ออริจินัล   แครกเกอร์ช้อคชิพ                 แครกเกอร์มะม่วง   \n",
       "2         แครกเกอร์ออริ  แคร็กเกอร์ช็อคชิพ         แครกเกอร์มะม่วงหิมพานต์   \n",
       "3   แครกเกอร์ออลริจินอล  แครกเกอร์ ช็อคชิพ                      แค็กมะม่วง   \n",
       "4      แครกเกอร์บราวนี่   แครกเกอร์ช็อกชิพ  แครกเกอร์บราวนี่มะม่วงหิมพานต์   \n",
       "..                  ...                ...                             ...   \n",
       "62                  NaN                NaN                             NaN   \n",
       "63                  NaN                NaN                             NaN   \n",
       "64                  NaN                NaN                             NaN   \n",
       "65                  NaN                NaN                             NaN   \n",
       "66                  NaN                NaN                             NaN   \n",
       "\n",
       "      cracker_almond                  oreo_ori               oreo_choc  ...  \\\n",
       "0   แครกเกอร์อัลม่อน                โอริโอออริ           โอริโอช็อคชิพ  ...   \n",
       "1   แครกเกอร์อัลม่อน               โอริโอ ออริ           โอริโอช้อคชิพ  ...   \n",
       "2   แครกเกอร์อัลมอนด  โอริโอ้บราวนี่ ออริจินอล  โอริโอ้บราวนี่ ช็อคชิพ  ...   \n",
       "3     แคกเกอร์อัลมอน        โอริโอ้บราวนี่ออริ          โอริโอ้ช็อกชิพ  ...   \n",
       "4   แคกเกอร์อัลมอนด์           โอริโอ้ บราวนี่          โอรีโอ้ช็อคชิพ  ...   \n",
       "..               ...                       ...                     ...  ...   \n",
       "62               NaN                       NaN                     NaN  ...   \n",
       "63               NaN                       NaN                     NaN  ...   \n",
       "64               NaN                       NaN                     NaN  ...   \n",
       "65               NaN                       NaN                     NaN  ...   \n",
       "66               NaN                       NaN                     NaN  ...   \n",
       "\n",
       "     cookie_coco cookie_coffee cookie_matcha          tart_ori  \\\n",
       "0   คุ้กกี้โกโก้   คุ้กกี้กาแฟ  คุ้กกี้มัทฉะ  ทาร์ตบราวนี่ออริ   \n",
       "1   คุกกี้โก้โก้    คุกกี้กาแฟ   คุกกี้มัดฉะ      ทาร์ตบราวนี่   \n",
       "2     คุกกี้ซ็อก   คุกกกี้กาแฟ   คุกกี้มัmฉะ      ทาร์ตบราวนี่   \n",
       "3     คุกกี้ช้อก   คุกกี้กาเเฟ  คุ้กกี้มัจฉะ         ทาร์ตออริ   \n",
       "4    คุกกี้โกโก้           NaN   คุกกี้มัจฉะ      ทาร์ตบราวนี่   \n",
       "..           ...           ...           ...               ...   \n",
       "62           NaN           NaN           NaN               NaN   \n",
       "63           NaN           NaN           NaN               NaN   \n",
       "64           NaN           NaN           NaN               NaN   \n",
       "65           NaN           NaN           NaN               NaN   \n",
       "66           NaN           NaN           NaN               NaN   \n",
       "\n",
       "                tart_choc               tart_mango             tart_almond  \\\n",
       "0     ทาร์ตบราวนี่ช้อคชิพ       ทาร์ตบราวนี่มะม่วง     ทาร์ตบราวนี่อัลม่อน   \n",
       "1            ทาร์ตช็อคชิพ      ทาร์ตหน้าเม็ดมะม่วง           ทาร์ตอัลมอนด์   \n",
       "2    ทาร์ตบราวนี่ ช็อคชิพ  ทาร์ตบราวนี่ เม็ดมะม่วง  ทาร์ตบราวนี่หน้าอัลมอน   \n",
       "3     ทาร์ตบราวนี่ช็อคชิพ      ทาตบาวนี่เม็ดมะม่วง      ทาร์ตบราวนี่อัลมอล   \n",
       "4            ทาร์ตช็อกชิพ                      NaN           ทาร์อัดลมอนด์   \n",
       "..                    ...                      ...                     ...   \n",
       "62                    NaN                      NaN                     NaN   \n",
       "63                    NaN                      NaN                     NaN   \n",
       "64                    NaN                      NaN                     NaN   \n",
       "65                    NaN                      NaN                     NaN   \n",
       "66                    NaN                      NaN                     NaN   \n",
       "\n",
       "           brownie_mash             stick chocball  \n",
       "0   บราวนี่มาร์ชแมลโลว์           ปังแท่ง  ช็อคบอล  \n",
       "1      บราวนี่มาชเมลโล่       ปังแท่งช้อค      NaN  \n",
       "2    มาร์ชเมลโล่บราวนี่           ปังแห้ง      NaN  \n",
       "3      บราวนี่มาชเมนโลว          ปังเเท่ง      NaN  \n",
       "4             มาชเมลโล่  ปังแท่งดาร์กช๊อก      NaN  \n",
       "..                  ...               ...      ...  \n",
       "62                  NaN               NaN      NaN  \n",
       "63                  NaN               NaN      NaN  \n",
       "64                  NaN               NaN      NaN  \n",
       "65                  NaN               NaN      NaN  \n",
       "66                  NaN               NaN      NaN  \n",
       "\n",
       "[67 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  Complete pipeline for training a machine learning model \n",
    "\n",
    "It uses the TF-IDF vectorization technique and Logistic Regression as the classifier. To classify text data into different categories based on the words provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 The code preprocesses text data for a machine learning project by converting it to lowercase and removing non-alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for column in order_category.columns:\n",
    "    category_name = column\n",
    "    words = order_category[column].explode().dropna().tolist()\n",
    "    data.extend(words)\n",
    "    labels.extend([category_name] * len(words))\n",
    "\n",
    "# Data preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
    "    return text\n",
    "\n",
    "data = [preprocess_text(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4177215189873418\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       brownie_mash       0.00      0.00      0.00         3\n",
      "      cookie_butter       1.00      0.50      0.67         2\n",
      "        cookie_coco       1.00      1.00      1.00         1\n",
      "      cookie_matcha       1.00      1.00      1.00         1\n",
      "       cracker_choc       1.00      0.67      0.80         3\n",
      "      cracker_mango       0.00      0.00      0.00         2\n",
      "        cracker_ori       0.00      0.00      0.00         2\n",
      "  cube_almond_check       1.00      0.38      0.55         8\n",
      "cube_chocship_check       0.27      0.88      0.41        17\n",
      "   cube_mango_check       1.00      0.12      0.22         8\n",
      "     cube_ori_check       0.50      0.38      0.43        13\n",
      "        oreo_almond       1.00      0.33      0.50         3\n",
      "          oreo_choc       1.00      0.67      0.80         3\n",
      "         oreo_mango       1.00      0.50      0.67         2\n",
      "           oreo_ori       0.00      0.00      0.00         4\n",
      "              stick       0.00      0.00      0.00         2\n",
      "        tart_almond       0.00      0.00      0.00         1\n",
      "          tart_choc       0.00      0.00      0.00         1\n",
      "         tart_mango       0.00      0.00      0.00         1\n",
      "           tart_ori       0.00      0.00      0.00         2\n",
      "\n",
      "           accuracy                           0.42        79\n",
      "          macro avg       0.49      0.32      0.35        79\n",
      "       weighted avg       0.53      0.42      0.38        79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\banas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\banas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\banas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Model selection and training (Logistic Regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RandomForestClassifier to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5189873417721519\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       brownie_mash       0.00      0.00      0.00         3\n",
      "      cookie_butter       1.00      0.50      0.67         2\n",
      "        cookie_coco       1.00      1.00      1.00         1\n",
      "      cookie_matcha       1.00      1.00      1.00         1\n",
      "       cracker_choc       1.00      0.67      0.80         3\n",
      "      cracker_mango       0.00      0.00      0.00         2\n",
      "        cracker_ori       0.00      0.00      0.00         2\n",
      "  cube_almond_check       1.00      0.38      0.55         8\n",
      "cube_chocship_check       0.27      0.88      0.41        17\n",
      "   cube_mango_check       1.00      0.12      0.22         8\n",
      "     cube_ori_check       0.50      0.38      0.43        13\n",
      "        oreo_almond       1.00      0.33      0.50         3\n",
      "          oreo_choc       1.00      0.67      0.80         3\n",
      "         oreo_mango       1.00      0.50      0.67         2\n",
      "           oreo_ori       0.00      0.00      0.00         4\n",
      "              stick       0.00      0.00      0.00         2\n",
      "        tart_almond       0.00      0.00      0.00         1\n",
      "          tart_choc       0.00      0.00      0.00         1\n",
      "         tart_mango       0.00      0.00      0.00         1\n",
      "           tart_ori       0.00      0.00      0.00         2\n",
      "\n",
      "           accuracy                           0.42        79\n",
      "          macro avg       0.49      0.32      0.35        79\n",
      "       weighted avg       0.53      0.42      0.38        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluation\n",
    "rf_accuracy = rf_model.score(X_test_tfidf, y_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training models using Thai language data, we observed an accuracy of 42% for Logistic Regression and 52% for RandomForestClassifier. To improve performance, I decided to switch the language from Thai to English before retraining the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Translate Data Collection from Thai to English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 Using GoogleTranslator from deep_translator library to translate thai to english and then saved the translated data to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for the translated text\n",
    "translated_df = pd.DataFrame()\n",
    "\n",
    "# Translate each column in the order_category DataFrame\n",
    "for column in order_category.columns:\n",
    "    # Translate the text in each cell of the column\n",
    "    translated_column = order_category[column].apply(lambda x: GoogleTranslator(source='th', target='en').translate(x) if pd.notnull(x) else x)\n",
    "    # Add the translated column to the translated DataFrame\n",
    "    translated_df[column] = translated_column\n",
    "\n",
    "# Display the translated DataFrame\n",
    "print(translated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_df.to_excel('Label/Order_Categories_En.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Complete Pipeline for Training a Machine Learning Model Using a Dataset That Contains Buyer Messages in English Language\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_categories_en = pd.read_excel('Label/Order_Categories_En.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 The code preprocesses text data for a machine learning project by converting it to lowercase and removing non-alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the data and labels from the DataFrame\n",
    "data = []\n",
    "labels = []\n",
    "for column in order_categories_en.columns:\n",
    "    # Check if the column is numeric, and skip if it is\n",
    "    if pd.api.types.is_numeric_dtype(order_categories_en[column].dtype):\n",
    "        continue\n",
    "    # Drop NaN values and convert to string\n",
    "    column_data = order_categories_en[column].dropna().astype(str)\n",
    "    data.extend(column_data)  # Add column data to the data list\n",
    "    labels.extend([column] * len(column_data))  # Assign labels for each column\n",
    "\n",
    "# Data preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Check if the text is NaN\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
    "    return text\n",
    "\n",
    "# Preprocess the data\n",
    "data = [preprocess_text(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8607594936708861\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       brownie_mash       1.00      1.00      1.00         3\n",
      "      cookie_butter       1.00      1.00      1.00         2\n",
      "        cookie_coco       1.00      1.00      1.00         1\n",
      "      cookie_matcha       1.00      1.00      1.00         1\n",
      "       cracker_choc       1.00      1.00      1.00         3\n",
      "      cracker_mango       1.00      0.50      0.67         2\n",
      "        cracker_ori       1.00      1.00      1.00         2\n",
      "  cube_almond_check       1.00      0.75      0.86         8\n",
      "cube_chocship_check       0.74      1.00      0.85        17\n",
      "   cube_mango_check       0.80      1.00      0.89         8\n",
      "     cube_ori_check       0.86      0.92      0.89        13\n",
      "        oreo_almond       1.00      1.00      1.00         3\n",
      "          oreo_choc       1.00      0.67      0.80         3\n",
      "         oreo_mango       1.00      1.00      1.00         2\n",
      "           oreo_ori       1.00      1.00      1.00         4\n",
      "              stick       0.00      0.00      0.00         2\n",
      "        tart_almond       1.00      1.00      1.00         1\n",
      "          tart_choc       0.00      0.00      0.00         1\n",
      "         tart_mango       0.00      0.00      0.00         1\n",
      "           tart_ori       0.00      0.00      0.00         2\n",
      "\n",
      "           accuracy                           0.86        79\n",
      "          macro avg       0.77      0.74      0.75        79\n",
      "       weighted avg       0.82      0.86      0.83        79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\banas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\banas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\banas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Model selection and training (Logistic Regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training models using Thai language data, we observed an accuracy of 86% for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Model For use in Business Case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "\n",
    "# Save tfidf_vectorizer to file\n",
    "dump(tfidf_vectorizer, 'Model/tfidf_vectorizer.joblib')\n",
    "\n",
    "# Save model to file\n",
    "dump(model, 'Model/model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Data Prepossing For Piwpiw Bakery Dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_1_may = pd.read_csv('Dataset_Piwpiw_Bakery/01_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_1_may = order_1_may[['Order ID', 'SKU ID', 'Seller SKU', 'Product Name',\n",
    "                      'Buyer Username', 'Buyer Message', 'Seller Note', 'Created Time',\n",
    "                      'Quantity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_order = order_1_may"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Using Model with in Piwpiw Bakery Dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Order ID               SKU ID   Seller SKU  \\\n",
      "0   578789261783108011  1730077047741516698  Cookie-Love   \n",
      "1   578789330922998564  1730077047741516698  Cookie-Love   \n",
      "2   578789685465877364  1730225897534950298          NaN   \n",
      "3   578789685465877364  1730225897535015834          NaN   \n",
      "4   578789920077875708  1730077047741516698  Cookie-Love   \n",
      "5   578790142209001920  1730077047741516698  Cookie-Love   \n",
      "6   578790180919020318  1730077047741516698  Cookie-Love   \n",
      "7   578790294495791162  1730077047741516698  Cookie-Love   \n",
      "8   578790358550940427  1730077047741516698  Cookie-Love   \n",
      "9   578790369955055633  1730077047741516698  Cookie-Love   \n",
      "10  578790387261278314  1730077047741516698  Cookie-Love   \n",
      "11  578790482306566848  1730077047741516698  Cookie-Love   \n",
      "12  578790571237672977  1730077047741516698  Cookie-Love   \n",
      "13  578790664874789520  1730077047741516698  Cookie-Love   \n",
      "14  578790757362010671  1730077047741516698  Cookie-Love   \n",
      "15  578790833328523557  1730077047741516698  Cookie-Love   \n",
      "16  578791079847037912  1730077047741516698  Cookie-Love   \n",
      "17  578791191930570814  1730077047741516698  Cookie-Love   \n",
      "18  578791197418686658  1730077047741516698  Cookie-Love   \n",
      "19  578791212119918708  1730077047741516698  Cookie-Love   \n",
      "20  578791419538738008  1730077047741516698  Cookie-Love   \n",
      "\n",
      "                                         Product Name        Buyer Username  \\\n",
      "0   รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...        nuengthidatran   \n",
      "1   รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...           ifellinluvu   \n",
      "2   บราวนี่ คิวท์ 4 หน้าให้เลือก หวานน้อย เข้มข้น ...   grace.idkwhattosay1   \n",
      "3   บราวนี่ คิวท์ 4 หน้าให้เลือก หวานน้อย เข้มข้น ...   grace.idkwhattosay1   \n",
      "4   รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...               iiesrun   \n",
      "5   รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...            oranee5115   \n",
      "6   รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...           y3tkafrac.y   \n",
      "7   รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...            supuporn29   \n",
      "8   รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...              suda4895   \n",
      "9   รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...            watasomsai   \n",
      "10  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...             baiibuaa0   \n",
      "11  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...            sofear224_   \n",
      "12  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...               bbxxm29   \n",
      "13  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...     user9618346788478   \n",
      "14  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...                yergez   \n",
      "15  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...              pednarag   \n",
      "16  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...      keeratisrijan601   \n",
      "17  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...              pplphpoy   \n",
      "18  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...             meemi0347   \n",
      "19  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...  teerissara_khongleng   \n",
      "20  รักหนูมั๊ยย 3กระปุก ราคา100 คุ้กกี้ฉ่ำโบ๊ะ หวา...                _zgpil   \n",
      "\n",
      "                                        Buyer Message  Seller Note  \\\n",
      "0                                                 NaN          NaN   \n",
      "1   คิวบ์ ออริจินอล, คิวบ์ช็อคชิพ, คิวบ์ มะม่วงหิม...          NaN   \n",
      "2                                                 NaN          NaN   \n",
      "3                                                 NaN          NaN   \n",
      "4                                                 NaN          NaN   \n",
      "5        คุกกี้เนยนม,  คิวบ์ออริจินอล,  คิวบ์อัลมอลด์          NaN   \n",
      "6     คิวบ์ ช็อคชิพ, คิวบ์ อัลมอลด์, คิวบ์ ออริจินอล,          NaN   \n",
      "7                              ออริจินอล 4, ช็อคชิพ 2          NaN   \n",
      "8                                                 NaN          NaN   \n",
      "9                                     คิวบ์ ออริจินอล          NaN   \n",
      "10           เอาบราวนี่ 3 กระปุกเลยค่ะ (คิวบ์ ออริจิ)          NaN   \n",
      "11                                                NaN          NaN   \n",
      "12      คิวบ์ ออริจินอล, คิวบ์ อัลมอนด์, คุกกี้ มัจฉะ          NaN   \n",
      "13       คิวบ์ ช็อคชิพ,  คิวบ์ ช็อคชิพ,  คุกกี้ โกโก้          NaN   \n",
      "14  คิวบ์อัลม่อน, คิวบ์เม็ดมะม่วง,  โอริโอ้บราวนี่...          NaN   \n",
      "15  คิวบ์ออริจินอล,   คิวบ์ช็อกชิพ,   โอริโอ้บราวน...          NaN   \n",
      "16                                                NaN          NaN   \n",
      "17               คิวบ์อออิริจินอล2, คุกกี้เนยนม1 ค้าา          NaN   \n",
      "18                                                NaN          NaN   \n",
      "19                                                NaN          NaN   \n",
      "20                                                NaN          NaN   \n",
      "\n",
      "             Created Time  Quantity brownie_mash  ... oreo_choc oreo_kitkat  \\\n",
      "0   01/05/2024 10:48:44\\t         1          NaN  ...       NaN         NaN   \n",
      "1   01/05/2024 11:10:13\\t         1          NaN  ...       NaN         NaN   \n",
      "2   01/05/2024 12:58:23\\t         1          NaN  ...       NaN         NaN   \n",
      "3   01/05/2024 12:58:23\\t         1          NaN  ...       NaN         NaN   \n",
      "4   01/05/2024 14:10:27\\t         1          NaN  ...       NaN         NaN   \n",
      "5   01/05/2024 15:21:17\\t         1          NaN  ...       NaN         NaN   \n",
      "6   01/05/2024 15:31:44\\t         1          NaN  ...       NaN         NaN   \n",
      "7   01/05/2024 16:05:58\\t         2          NaN  ...       NaN         NaN   \n",
      "8   01/05/2024 16:30:30\\t         2          NaN  ...       NaN         NaN   \n",
      "9   01/05/2024 16:34:13\\t         1          NaN  ...       NaN         NaN   \n",
      "10  01/05/2024 16:44:13\\t         1          NaN  ...       NaN         NaN   \n",
      "11  01/05/2024 17:18:28\\t         1          NaN  ...       NaN         NaN   \n",
      "12  01/05/2024 17:50:02\\t         1          NaN  ...       NaN         NaN   \n",
      "13  01/05/2024 18:25:35\\t         1          NaN  ...       NaN         NaN   \n",
      "14  01/05/2024 18:59:03\\t         1          NaN  ...       NaN         NaN   \n",
      "15  01/05/2024 19:24:48\\t         1          NaN  ...         1         NaN   \n",
      "16  01/05/2024 20:34:06\\t         1          NaN  ...       NaN         NaN   \n",
      "17  01/05/2024 21:04:33\\t         1          NaN  ...       NaN         NaN   \n",
      "18  01/05/2024 21:08:08\\t         1          NaN  ...       NaN         NaN   \n",
      "19  01/05/2024 21:09:51\\t         1          NaN  ...       NaN         NaN   \n",
      "20  01/05/2024 22:04:44\\t         1          NaN  ...       NaN         NaN   \n",
      "\n",
      "   oreo_mango oreo_ori stick tart_almond tart_choc tart_mango tart_ori random  \n",
      "0         NaN      NaN   NaN         NaN       NaN        NaN      NaN    1.0  \n",
      "1         NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "2         NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "3         NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "4         NaN      NaN   NaN         NaN       NaN        NaN      NaN    1.0  \n",
      "5         NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "6         NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "7         NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "8         NaN      NaN   NaN         NaN       NaN        NaN      NaN    1.0  \n",
      "9         NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "10        NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "11        NaN      NaN   NaN         NaN       NaN        NaN      NaN    1.0  \n",
      "12        NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "13        NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "14        NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "15        NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "16        NaN      NaN   NaN         NaN       NaN        NaN      NaN    1.0  \n",
      "17        NaN      NaN   NaN         NaN       NaN        NaN      NaN    0.0  \n",
      "18        NaN      NaN   NaN         NaN       NaN        NaN      NaN    1.0  \n",
      "19        NaN      NaN   NaN         NaN       NaN        NaN      NaN    1.0  \n",
      "20        NaN      NaN   NaN         NaN       NaN        NaN      NaN    1.0  \n",
      "\n",
      "[21 rows x 34 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
      "C:\\Users\\banas\\AppData\\Local\\Temp\\ipykernel_7700\\1132558142.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Load the TF-IDF vectorizer and the model\n",
    "tfidf_vectorizer = load('Model/tfidf_vectorizer.joblib')\n",
    "loaded_model = load('Model/model.joblib')\n",
    "\n",
    "# Initialize an empty DataFrame to store predicted categories\n",
    "predicted_categories_df = pd.DataFrame(columns=loaded_model.classes_)\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in counting_order.iterrows():\n",
    "    # Initialize a dictionary to store predicted categories for each word\n",
    "    predicted_categories = {}\n",
    "    \n",
    "    # Check if the value in the \"Buyer Message\" column is a string\n",
    "    if isinstance(row['Buyer Message'], str):\n",
    "        # Split the text in the \"Buyer Message\" column by comma and space\n",
    "        words = row['Buyer Message'].split(', ')\n",
    "        \n",
    "        # Predict category for each word\n",
    "        for word in words:\n",
    "            # Translate the word from Thai to English\n",
    "            translated_word = GoogleTranslator(source='th', target='en').translate_batch([word])[0]\n",
    "            # Use TF-IDF vectorizer to transform the translated word\n",
    "            word_tfidf = tfidf_vectorizer.transform([translated_word])\n",
    "            # Predict the category for the word using the loaded model\n",
    "            predicted_category = loaded_model.predict(word_tfidf)[0]\n",
    "            # Check if there is any number in the translated word\n",
    "            number = ''.join(filter(str.isdigit, translated_word))\n",
    "            if number:\n",
    "                predicted_categories[predicted_category] = int(number)\n",
    "            else:\n",
    "                predicted_categories[predicted_category] = 1\n",
    "    \n",
    "    # Check if the value in the \"Seller Note\" column is a string\n",
    "    if isinstance(row['Seller Note'], str):\n",
    "        # Split the text in the \"Seller Note\" column by comma and space\n",
    "        words = row['Seller Note'].split(', ')\n",
    "        \n",
    "        # Predict category for each word\n",
    "        for word in words:\n",
    "            # Translate the word from Thai to English\n",
    "            translated_word = GoogleTranslator(source='th', target='en').translate_batch([word])[0]\n",
    "            # Use TF-IDF vectorizer to transform the translated word\n",
    "            word_tfidf = tfidf_vectorizer.transform([translated_word])\n",
    "            # Predict the category for the word using the loaded model\n",
    "            predicted_category = loaded_model.predict(word_tfidf)[0]\n",
    "            # Check if there is any number in the translated word\n",
    "            number = ''.join(filter(str.isdigit, translated_word))\n",
    "            if number:\n",
    "                predicted_categories[predicted_category] = int(number)\n",
    "            else:\n",
    "                predicted_categories[predicted_category] = 1\n",
    "    \n",
    "    # Check additional condition and assign values to 'random' column\n",
    "    if row['Seller SKU'] == 'Cookie-Love' and pd.isna(row['Buyer Message']) and pd.isna(row['Seller Note']):\n",
    "        predicted_categories['random'] = 1\n",
    "    else:\n",
    "        predicted_categories['random'] = 0\n",
    "\n",
    "    # Add the predicted categories to the DataFrame\n",
    "    predicted_categories_df = predicted_categories_df.append(predicted_categories, ignore_index=True)\n",
    "     \n",
    "# Concatenate the predicted categories DataFrame with the original data_new DataFrame\n",
    "result_df = pd.concat([counting_order, predicted_categories_df], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order ID', 'SKU ID', 'Seller SKU', 'Product Name', 'Buyer Username',\n",
       "       'Buyer Message', 'Seller Note', 'Created Time', 'Quantity',\n",
       "       'brownie_mash', 'chocball', 'cookie_butter', 'cookie_coco',\n",
       "       'cookie_coffee', 'cookie_matcha', 'cracker_almond', 'cracker_choc',\n",
       "       'cracker_mango', 'cracker_ori', 'cube_almond_check',\n",
       "       'cube_chocship_check', 'cube_mango_check', 'cube_ori_check',\n",
       "       'oreo_almond', 'oreo_choc', 'oreo_kitkat', 'oreo_mango', 'oreo_ori',\n",
       "       'stick', 'tart_almond', 'tart_choc', 'tart_mango', 'tart_ori',\n",
       "       'random'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test accuracy after using with Piwpiw Bakery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_check = pd.read_excel('Dataset_for_check/01_05_version1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['brownie_mash', 'chocball', 'cookie_butter', 'cookie_coco',\n",
    "                    'cookie_coffee', 'cookie_matcha', 'cracker_almond', 'cracker_choc',\n",
    "                    'cracker_mango', 'cracker_ori', 'cube_almond_check',\n",
    "                    'cube_chocship_check', 'cube_mango_check', 'cube_ori_check',\n",
    "                    'oreo_almond', 'oreo_choc', 'oreo_kitkat', 'oreo_mango', 'oreo_ori',\n",
    "                    'stick', 'tart_almond', 'tart_choc', 'tart_mango', 'tart_ori',\n",
    "                    'random']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[columns_to_check] = result_df[columns_to_check].fillna(0)\n",
    "\n",
    "# If you want to convert the columns to integer type as well\n",
    "result_df[columns_to_check] = result_df[columns_to_check].astype(int)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_check[columns_to_check] = data_for_check[columns_to_check].fillna(0)\n",
    "\n",
    "# If you want to convert the columns to integer type as well\n",
    "data_for_check[columns_to_check] = data_for_check[columns_to_check].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'brownie_mash':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'chocball':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cookie_butter':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cookie_coco':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cookie_coffee':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cookie_matcha':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cracker_almond':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cracker_choc':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cracker_mango':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cracker_ori':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cube_almond_check':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cube_chocship_check':\n",
      "  Match Percentage: 90.48%\n",
      "  Differences:\n",
      "    Row 10: 3 (result_df) != Row 10: 0 (data_for_check)\n",
      "    Row 13: 1 (result_df) != Row 13: 2 (data_for_check)\n",
      "Column 'cube_mango_check':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'cube_ori_check':\n",
      "  Match Percentage: 90.48%\n",
      "  Differences:\n",
      "    Row 9: 1 (result_df) != Row 9: 3 (data_for_check)\n",
      "    Row 10: 0 (result_df) != Row 10: 3 (data_for_check)\n",
      "Column 'oreo_almond':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'oreo_choc':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'oreo_kitkat':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'oreo_mango':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'oreo_ori':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'stick':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'tart_almond':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'tart_choc':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'tart_mango':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'tart_ori':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n",
      "Column 'random':\n",
      "  Match Percentage: 100.00%\n",
      "  Differences:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_dataframes(df1, df2, columns_to_check):\n",
    "    diff_dict = {}\n",
    "    for column in columns_to_check:\n",
    "        if column in df1.columns and column in df2.columns:\n",
    "            match_count = 0\n",
    "            total_count = 0\n",
    "            diffs = []\n",
    "            for idx, (val1, val2) in enumerate(zip(df1[column], df2[column])):\n",
    "                if pd.isna(val1) and pd.isna(val2):\n",
    "                    continue  # Treat NaN values as matches\n",
    "                elif val1 != val2:\n",
    "                    diffs.append((idx, val1, val2))\n",
    "                else:\n",
    "                    match_count += 1\n",
    "                total_count += 1\n",
    "            match_percentage = (match_count / total_count) * 100 if total_count > 0 else 0\n",
    "            diff_dict[column] = {'matches': match_percentage, 'differences': diffs}\n",
    "    return diff_dict\n",
    "\n",
    "# Compare the DataFrames\n",
    "differences = compare_dataframes(result_df, data_for_check, columns_to_check)\n",
    "\n",
    "# Print the differences and match percentages\n",
    "for column, info in differences.items():\n",
    "    print(f\"Column '{column}':\")\n",
    "    print(f\"  Match Percentage: {info['matches']:.2f}%\")\n",
    "    print(\"  Differences:\")\n",
    "    for idx, val1, val2 in info['differences']:\n",
    "        print(f\"    Row {idx}: {val1} (result_df) != Row {idx}: {val2} (data_for_check)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = []\n",
    "match_percentage_list = []\n",
    "\n",
    "\n",
    "# Iterate over the differences dictionary\n",
    "for column, info in differences.items():\n",
    "    columns_list.append(column)\n",
    "    match_percentage_list.append(info['matches'])\n",
    "\n",
    "\n",
    "# Construct DataFrame\n",
    "difference_df = pd.DataFrame({\n",
    "    'Column': columns_list,\n",
    "    'Match Percentage': match_percentage_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Match Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brownie_mash</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chocball</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookie_butter</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cookie_coco</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cookie_coffee</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cookie_matcha</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cracker_almond</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cracker_choc</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cracker_mango</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cracker_ori</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cube_almond_check</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cube_chocship_check</td>\n",
       "      <td>90.47619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cube_mango_check</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cube_ori_check</td>\n",
       "      <td>90.47619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oreo_almond</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>oreo_choc</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oreo_kitkat</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>oreo_mango</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>oreo_ori</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stick</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tart_almond</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tart_choc</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tart_mango</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tart_ori</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>random</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Column  Match Percentage\n",
       "0          brownie_mash         100.00000\n",
       "1              chocball         100.00000\n",
       "2         cookie_butter         100.00000\n",
       "3           cookie_coco         100.00000\n",
       "4         cookie_coffee         100.00000\n",
       "5         cookie_matcha         100.00000\n",
       "6        cracker_almond         100.00000\n",
       "7          cracker_choc         100.00000\n",
       "8         cracker_mango         100.00000\n",
       "9           cracker_ori         100.00000\n",
       "10    cube_almond_check         100.00000\n",
       "11  cube_chocship_check          90.47619\n",
       "12     cube_mango_check         100.00000\n",
       "13       cube_ori_check          90.47619\n",
       "14          oreo_almond         100.00000\n",
       "15            oreo_choc         100.00000\n",
       "16          oreo_kitkat         100.00000\n",
       "17           oreo_mango         100.00000\n",
       "18             oreo_ori         100.00000\n",
       "19                stick         100.00000\n",
       "20          tart_almond         100.00000\n",
       "21            tart_choc         100.00000\n",
       "22           tart_mango         100.00000\n",
       "23             tart_ori         100.00000\n",
       "24               random         100.00000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Match Percentage: 99.23809523809523\n"
     ]
    }
   ],
   "source": [
    "Overall_match_percentage = difference_df['Match Percentage'].mean()\n",
    "\n",
    "print(\"Overall Match Percentage:\", Overall_match_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel('Dataset_Counting/01_05_counting.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
